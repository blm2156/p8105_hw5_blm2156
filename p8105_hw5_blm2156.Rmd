---
title: "p8105_hw5_blm2156"
author: "Britney Mazzetta"
output: github_document
---

# Problem 1

```{r}
library(tidyverse)
library(patchwork)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>%
  janitor::clean_names()

function1 = function(x) {
  
  if(is.numeric(x)) {
    replace_na(x, round(mean(x, na.rm = TRUE)))
  } else if (is.character(x)) {
    replace_na(x, "virginica")
  }
}

iris_final = map_df(iris_with_missing, function1)
iris_final
```

# Problem 2

```{r}
problem2_files = list.files("./data/", full.names = TRUE)

p2_data = problem2_files %>%
  map(read_csv) %>%
  reduce(rbind) %>%
  mutate(
    subject_id = c(1:20),
    study_arm = ifelse(subject_id == c(1:10), "control", "experimental")) %>%
  select(subject_id, study_arm, everything())
p2_data
```

## Spaghetti Plot

```{r}
p2_spaghetti = p2_data %>%
  pivot_longer(
  week_1:week_8,
  names_to = "week", 
  values_to = "value"
  ) %>% 
  separate(week,into = c("week_name", "week_number"), sep = 
  "_") %>%
  select(-week_name) %>%
  ggplot(aes(x = week_number, y = value, color = study_arm, group=subject_id)) + 
  geom_point() + 
  geom_line() +
  labs(
    title = "Observations on each subject over time",
    x = "Week Number",
    y = "Value")
p2_spaghetti
```

The values observed in the experimental arm are higher than the values observed in the control arm. As weeks increase, the values tend to increase in the experimental arm, while the values in the control arm appear to remain relatively constant. With time, the difference between the experimental and control group appears to increase. 

# Problem 3

```{r}
set.seed(1)

sim_regression = function(n= 30, beta0 = 2, beta1 = 0) {
 prob3 = tibble(
    x = rnorm(n, mean = 0, sd = 1), 
    y = beta0 + beta1 * x + rnorm(n, 0, sqrt (50))
  )

ls_fit = lm(y ~ x, data = prob3) %>%
  broom::tidy ()

tibble(
  beta1_hat = ls_fit[[2,2]],
  p_value = ls_fit [[2,5]]
)

}
```

```{r}
prob3_final = rerun(10000, sim_regression(beta1 = 0)) %>% 
  bind_rows()
```

```{r}
prob3_final2 = 
  tibble(beta1_new = c(0,1,2,3,4,5,6)) %>%
  mutate(
    output_lists = map(.x = beta1_new, ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>%
  select (-output_lists) %>%
  unnest(estimate_dfs)
```

## Plot 1
```{r}
p3_plot1 = prob3_final2 %>%
  mutate(reject = ifelse(p_value < 0.05, "Significant", "Not Significant")) %>%
  group_by(beta1_new, reject) %>%
  summarize(rejection_count = n()) %>%
  filter(reject == "Significant") %>%
  mutate(rejection_rate = rejection_count/100) %>%
ggplot(aes(x = beta1_new, y = rejection_rate)) + 
    geom_point() +
    geom_line() + 
    labs(
    title = "Relationship Between Power and Effect Size",
    x = "Effect Size",
    y = "Power")
p3_plot1

```

Based on the plot, as the effect size increases (true value of Beta 1), power tends to increase before level off and slowing its increase around power = 80+.

## Plot 2

```{r}
p3_plot2 = prob3_final2 %>%
  mutate(reject = ifelse(p_value < 0.05, "Significant", "Not Significant")) %>%
  group_by(beta1_new) %>%
  summarize(mean_b1= mean(beta1_hat)) %>%
ggplot(aes(x = beta1_new, y =mean_b1)) + 
    geom_point() +
    geom_line() + 
    labs(
    title = "Relationship Between True Value of Beta1 and Mean estimate of Beta 1",
    x = "True Value of beta1",
    y = "Mean estimate of Beta1")
p3_plot2
```

## Plot 3

```{r}
p3_plot3 = prob3_final2 %>%
  mutate(reject = ifelse(p_value < 0.05, "Significant", "Not Significant")) %>%
  filter(reject == "Significant") %>%
  group_by(beta1_new) %>%
  summarize(mean_b1= mean(beta1_hat)) %>%
ggplot(aes(x = beta1_new, y =mean_b1)) + 
    geom_point() +
    geom_line() + 
    labs(
    title = "Relationship Between True Value of Beta1 and Mean estimate of Beta 1 only in samples for which the null was rejected",
    x = "True Value of beta1",
    y = "Mean estimate of Beta1 only in samples for which the null was rejected")
p3_plot3
```

The sample average of Beta1 across tests for which the null is rejected is larger than the true value of Beta1. However, there still appears to be a somewhat linear relationship. Between effect size values of 0 and 4, the mean estimate of Beta1 is particularly overestimated when we are only considering values in which the null was rejected. 